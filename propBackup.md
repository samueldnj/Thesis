---  
title: "Managing for Technical Interactions in Groundfish Fisheries."
subtitle: Thesis Proposal
author: Samuel Johnson
date: \today
geometry: letterpaper
toc: true
abstract: Sustainable management of multi-species fisheries encounters several challenges. Generally, challenges include managing the impact of non-selective fishing efforts on target species, non-target species and habitats in an uncertain world. Managing under uncertainty requires ongoing monitoring of fish stocks through surveys and commercial data collection, consuming scientific and financial resources. For commercially important species in the fishery these resources are readily available due to profitability of fishing operations, but for stocks of low commercial importance resources are scarce. Data limitations can also preclude assessment for many non-target species. In the British Columbia groundfish fishery this situation has led to as many as half of exploited species going without stock assessments, threatening sustainable management by (i) weakening the link between stock status and management decisions and (ii) weakening access to seafood markets through lack of eco-certification.
---

# Introduction

## Background

Sustainable management of any renewable resource requires understanding of system dynamics in response to exploitation. In a multi-species fisheries context the system is a collection semi-discrete self-sustaining population of fish called *stocks* (@begg1999stock), and the exploitation involves removing individuals by fishing. Fishing efforts impact target species, non-target species and fish habitat, and a major challenge of multi-species fishery management is to balance these impacts with sustainability goals.

Sustainable and scientifically defensible fishery management is built on the foundation of fisheries stock assessment (@hilborn1992quantitative). Quantitative stock assessment methods combine elements of data science, applied population ecology, risk assessment and resource management. Analysts use data from multiple sources including scientific surveys and commercial fishery monitoring to infer biological and fishery dynamics and to characterise uncertainties in these assessments. These inferences include estimates of species abundance and productivity that are used to inform management decisions.

In Canada, stock assessments are lacking in most fisheries (@hutchings2012canada), especially for non-target species. One reason is that non-target species are typically of lower commercial importance, so there simply isn't enough money for assessments. Another reason is data limitations sometimes preclude the assessment of certain species. For instance, some fisheries may not conduct surveys with a suitable experimental design for a given non-target species (*reference to Yelloweye?*). This leaves managers with a choice between conducting a flawed assessment, or conducting no assessment at all.

A lack of assessments for some species within a multi-species fishery threatens sustainable management of the whole fishery in two ways. First, a lack of assessments creates conservation risks by weakening the link between management decisions and stock status. This is occuring in the British Columbia groundfish fishery with Rougheye-Blackspotted Rockfish (*S. aleutianus*; *S. melanostictus*). Second, eco-certifiers typically require proper assessments for all species captured, regardless of whether capture is intentional or not. For example, a lack of up-to-date assessments for non-target species makes it impossible to satisfy Principle 2 of the Marine Stewardship Council fisheries certification criteria. 


## Technical Interactions in Multi-Species Fisheries

Stock assessments are traditionally performed for a single species at a time, even though this approach may lead to sub-optimal outcomes for multi-species fisheries (@sugihara1984ecosystems; @gulland1984observed). Sub-optimal outcomes arise from not accounting for the effects of ecological and technical interactions between species. First, ecological interactions such as competitive (non-trophic) and predator-prey (trophic) interactions may bias estimates of species productivity (@mueter2006using). Second, technical interactions caused by non-selective fishing may be unaccounted for in a single species approach. By failing to account for interactions, both over- and under-exploitation can be caused by managing under the single-species paradigm.

Within the single-species paradigm, major stocks typically comprise several distinct but interacting sub-stocks (@walters2004fisheries; @benson2015evaluating), such as Pacfic salmon (*Onchorynchys spp.*) (@simon1972stock). Multiple ecologically and technically interacting populations (i.e., stocks) of Chinook (*O. tshawtcha*), Chum (*O. keta*), Coho (*O. kisutch*), Pink (*O. gorbausch*), Sockeye (*O. nerka*) and Steelhead (*O. mykiss*) occur along Canada's Pacific coast. Each species is made up of genetically distinct subpopulations, defined mainly by discrete spawning habitats that establish quasi-isolated reproductive populations (@ricker1972hereditary) connected by low straying rates. Managing hundreds of distinct stocks impractical (@walters2004fisheries), so salmon stocks are often grouped together into *stock complexes* for management and assessment. In the Fraser River, sub-populations of Chinook and Sockeye are grouped into aggregate stock complexes called runs, which are based on similarity in life history, geographical locations of spawning habitat and arrival timing to fisheries (@english2011fraser; @DFO1999Fraser-River-Ch).

Managing Pacific salmon in runs has both advantages and disadvantages. Advantages stem from more efficient management practices: stocks in the same Sockeye run are fished based on an estimate of sustainable yield for the whole run. While such aggregation might lead to underfishing of some stocks, there is a larger benefit from more reliable and less costly assessments of the run due to data pooling. A major disadvantage is overexploitation of the weakest member stock (@ricker1973two; @ricker1958maximum) due to an overestimate of productivity for the run. This occured in the Late run of Fraser river Sockeye, which was fished at the average maximum sustainable yield (MSY) for the run. The Late run MSY overexploited the Cultus Lake stock and brought it to the low abundance that it remains at today (*refs*). The solution for Late run Sockeye was to fish at the maximum yield for the weakest stock, meaning that the Late run is harvested at the maximum yield for the Cultus Lake stock. By managing for the weakest stock's productivity, multiple productivity levels are accommodated in an aggregate management system.

The aggregation management approach used for Pacific salmon could be extended to other multi-species fisheries rich with technical interactions, such as groundfish fisheries. Groundfish fisheries on the west coast of North America exploit stocks of sablefish, Pacific halibut (*Hippoglossus stenolopis*), several species of rockfish (*Sebastes spp.*), Pacific Cod (*Gadus macrocephalus*) and other species (@PRIFMP2015) **Include flatfish**. Groundfish species are fished by non-selective longline, trap and trawl gear, making technical interactions between species commonplace. 

- Managing groundfish would require a similar but distinct approach due to several key differences to Pacific Salmon.
    + Iteroparous species
    + Multiple species instead of just multiple stocks of the same species
    + data limitations

Technical interactions between fishes have led several groundfish fisheries in the north Pacific *(??)* to integrate harvest output controls by making shares of the Total Allowable Catch (TAC) for every species available to harvesters. Harvesters are then allowed to retain more catch from each fishing trip, reducing discarding of marketable fish.

- Para about FAO/fisheries lit: removals scaled to stock status? Requires assessment to estimate abundance and productivity. This scaling to stock size/status creates the pinch-points. This would also include information about SARA/COSEWIC species.

Although integration acknowledges technical interactions in multi-species groundfish fisheries through TAC distribution, challenges remain in managing integrated fisheries optimally. I focus on two challenges related to integration and technical interactions between high and low productivity stocks. First, integration requires setting a TAC for every stock encountered by the fishery, which is subject to problems of data-limitations for low importance species. Second, integration can cause a constraining effect on fishing profitability when weaker low productivity stocks interact with stronger high productivity stocks. Weaker stocks have lower TACs that are filled faster, constraining fishing of strong stocks with higher TACs and leading to an under-exploitation of high value stocks in integrated fisheries. Lower productivity fishes that constrain profitability due to technical interactions with higher productivity fishes are known colloquially as *pinch-point* species.

## Assess or Avoid

The profitability constraints on directed fisheries caused by pinch-point species may be alleviated by either assessing data-limited stocks, or avoiding pinch-point species. After assessment the TAC can be scaled to a more certain stock status and better estimates of stock productivity. This could have 2 effects: either the status is fair and the pinch-point created by the data-limitation can be removed, or the status is concerning and the pinch point remains. If the status of a species is known and it still constrains fishing of stronger stocks, then avoiding the weaker species can help to lift the constraint. I call this an assess or avoid management strategy.

One option for overcoming data limitations is to extend stock assessments to explicitly acknowledge interactions between species (@punt2011among; @zhou2010modified; @mueter2006using). Accounting for interactions explicitly acknowledges that individual fish stocks are part of a larger ecosystem containing multiple spatially and temporally overlapping species (@walters2004fisheries; @beverton1984dynamics). Statistical benefits from aggregating multiple species into a single assessment may allow previously unassessed species to be assessed. Knowledge of stock-status may the relieve constraints caused by pinch-point species and increase economic welfare to the fishery. While more complicated than the single specie paradigm, the benefit of assessing previously unassessed species may outweigh the costs.

Figure 2 shows three possible models of fishery operation and management. Model (a) is the status quo approach of single species stock assessment, where every stock is treated as a separate population (@hilborn1992quantitative). Model (b) keeps the data separate as in model (a), but performs assessments for groups of stocks using statistical models that link the data during estimation (@zhou2010modified; @punt2011among; @mueter2006using). Finally, model (c) is a total aggregation approach where several species or stocks have their data combined and are then assessed as a single stock (@sugihara1984ecosystems; @gulland1984observed) with TAC set for the aggregate; this is similar to the approach used for assessing Pacific salmon stocks (@english2011fraser). Models (b) and (c) could potentially be used in multi-species fisheries when model (a) is impractical due to data limitations. Models (b) and (c) may improve the confidence in quantitative results through the statistical benefits of aggregation, and may allow an assessment to be extended to a previously unassessed species.

I study a version of model (b) in Figure (1) that is called the Robin Hood (RH) approach to stock assessment. The RH approach requires a relatively novel statistical model that has seen limited application (@zhou2010modified; @punt2011among). The statistical model assumes a hierarchical structure of multi-species fisheries as shown in Figure 3 (**FIGURE**). This hierarchical structure is used to simultaneously assess multiple interacting species and exploit their technical interactions. Potential exploits are assuming correlations or similarities in assessment parameters such as recruitment, natural mortality and catchability (@punt2011among) due to environmental factors. 

***START LAYERING QUESTIONS INTO THIS EXPOSITION?***

The RH approach to stock assessment could help shape how scientific surveys are designed.
- More complicated assessments could be extended by sharing growth information between species with similar evolutionary biology
- If the risks are manageable, survey effort can be redistributed more efficiently based on the structure of assemblages assessed by the RH method.

To develop the avoidance part of the strategy, I use machine learning tools to analyse commercial data.
    - Describe ML (in 1 or 2 sentences)
    - Explain how some methods overcome statistical assumptions

- Identify assemblages based on need/interactions
    + pinch-point species are the guiding factor
    + Look at commercial catch data by gear type
        * What are the directed species?
        * What are the pinch-points?

**QUESTION:** What stocks constrain the profitability of directed fisheries?

- Now, what species out of those that constrain profitability are in need of a model-based assessment
    + Can we assess some with a swept-area assessment?
    + If we try, do we have any confidence in the results?

**QUESTION:** What stocks are unable to be assessed by more direct (absolute survey index) approaches with current survey data?

- Now, stocks that lack assessments, constrain profiability and *require* model based assessments need something new. We suggest the RH method might work for some.
+ Can we build assemblages for these stocks, suitable for the application of the RH method?

**QUESTION:** What assemblages of technically interacting stocks, which satisfy the previous 2 questions, exist in the BCIGF and are amenable to the RH method of stock assessment?

- Look through catch data
    + What other species are commonly fished/surveyed with the pinch-point?
    + Take a set-theoretic approach:
        * Look for intersections in habitat/extent and technical interactions.
    + Can we extend the stock concept to an assemblage?

- Statistical properties of the RH model
    + not well studied, but qualitative differences in the assessments of data-poor species
    + We want to quantify the effect: bias and precision

**QUESTION:** What are the bias and precision of estimates of leading stock assessment parameters produced by the RH method of stock assessment?


- Management performance of the RH model
    - Risks of MS management?
        + Contrast between species
        + data quality issues
        + Real risk is of overfish, F > F_{MSY}

**QUESTION:** What are the risks associated with using the RH method of assessment under varying levels of (a) data-quality (b) technical interactions?

- Test this using closed loop simulation.
    + Test over a range of scenarioes, plot probability of F > F_{MSY} for different values of target F

- Another use of the RH method could be to make survey design more efficient
    + Can we exploit evolutionary biology in complexes of similar fish to reduce the cost of surveys
        * eg: length sample some species, age sample others, share information on growth

**QUESTION:** How can surveys be designed to take advantage of the information sharing qualities of the RH method, while at the same time keeping risk manageable?

- What if assessments don't help? How can we increase profitability and conservation otherwise, relieve the effect of pinch-point species?
    + Avoidance techniques
    + Dynamic Ocean Management (DOM) @dunn2016dynamic
    + Can we use the data provided by the fishery better?

**QUESTION:** What is the feasibility of a data-based approach to avoiding non-target species in a multi-species fishery?

- We can use machine learning techniques to analyse commercial data.
    + Some ML techniques side-step the issue of experimental design
    + Test feasibility using classification of presence/absence:
        * Direct measurement of error rates of classifiers (1st stage)
        * Area under ROC curve to trade off between false positives and false negatives

**QUESTION:** What are the important predictors for the presence of juvenile Sablefish in commercial catch in the trawl and trap sectors?

- This will be answered by performing model selection on a classifier
    + RF variable importance
    + Lasso approach?
- Adding environmental predictors should be tested
    + oceanography
    + weather

**QUESTION:** What are the important predictors for (a) CPUE and (b) biomass of juvenile Sablefish in commercial catch in BC trawl and trap fisheries?

- Again, we'll do some model selection, testing a few different models
    + ML classification on ordinal, categorical descretisation of catch/CPUE
    + ML regression on raw data
    + Hurdle model, which classifies pres/abs then regresses for presence.
        * Requires a choice of threshold probability




<!-- Biological and fishery interactions among species, stocks and fisheries fall into four general types. Predator-prey relationships fall within *trophic interactions* that contribute to growth and natural mortality of predator and prey species, while inter- and intra-specific competition for food and habitat fall within *competitive interactions* that limit growth and mortality of species. *Technical interactions* occur where the spatial and temporal distributions of species overlap and they appear together in fishery catch. The term technical interactions is also used to describe competitive externalities due to fishing vessels or gear operating on the same grounds and exploiting the same resource (@ulrich2001estimation), however to avoid confusion I define these as *fishery interactions*.
 -->




<!-- Fraser River Sockeye salmon consist of 19 stocks managed in 4 aggregate complexes: Early Stuart, Early Summer, Summer and Late. Managing 4 aggregates based on biological, technical and fishery interactions instead of 19 member stocks has both benefits and challenges. Benefits include an increase in the practicality of management (@walters2004fisheries) and the aggregation of data for complexes, making it easier to separate the signal from the noise when making inferences about life history parameters. The major challenge of aggregation is related to the second benefit: managing for the aggregate can lead to overexploitation of the weakest member (@ricker1973two; @ricker1958maximum) due to an overestimate of productivity, such was the case of the Cultus Lake stock of Sockeye salmon. The solution is to fish the aggregate complexes at the maximum yield for the member stock with the lowest productivity, meaning that the Late run is harvested at the maximum yield for the Cultus Lake stock. Productivity of member stocks is determined through genetic sampling of the aggregate catch, however sometimes smaller stocks are either under-represented or missed altogether.
 -->  





<!-- Setting a TAC proportional to stock-size, such as a harvest rate, requires estimates of abundance and productivity. Abundance and productivity are estimated through stock assessment, so setting a TAC for each stock in a fishery requires an assessment of each stock. Each assessment requires estimates of fishery dependent removals and fishery-independent indices of abundance, as well as the capital resources to collect, process and store the required data and perform the assessment. Each stage of data preparation is a potential source of uncertainty (@hilborn1992quantitative, Ch. 15), and in some cases data collection and quality issues can preclude assessment altogether. If quota is required and no assessment is available the TAC is often set the same as the previous year, possibly allowing overfishing to go undetected. This phenomenon is realised in multi-species fisheries, where data quality and availability correlates with commercial importance. Stocks of low importance are often left unassessed and TACs are set without scientific basis.
 -->
<!-- Regular assessments of all stocks in multi-species fisheries would enable managers to set scientifically defensible TACs, an important basis for a modern fishery (refs). These TACs will more accurately reflect the status of the resource and help to identify over exploitation when it exists. Furthermore, there are several conceivable benefits to expanded assessments in a multi-species fishery; I outline two. First, eco-certification companies such as the Marine Stewardship Council (MSC) require regular assessments to satisfy MSC Principle 1: "Sustainable Fish Stocks". Second, assessments of low-importance stocks can help to bring management actions into line with fishery objectives, when the two might have diverged without the knowledge provided by stock assessments.
 -->





<!-- Assessment methods that make better use of existing resources could be invaluable in multi-species fisheries where some stocks have too little data to support conventional stock assessments. Stocks for which conventional assessments are not possible with existing data-streams are termed *data-limited* (@ices2012implementation) and typically correspond to lower value or bycatch species in multi-species fisheries; I call a multi-species fishery *data-variable* when it contains stocks that are data-limited and stocks that are not. An example of a data-variable fishery is the British Columbia Integrated Groundfish Fishery (BCIGF) that operates multiple gear types within 55 stock-area combinations across 9 management units (@PRIFMP2015). High value species in the BCIGF, such as halibut (*Hippoglosus stenolepis*) and sablefish (*Anoplopoma fimbria*), have dedicated surveys and regular stock assessments to set TAC annually, while lower value and bycatch species, such as certain rockfish (*Sebastes spp.*) species are fished under quota limits that are set either using out of date assessments or assessments based on dubious data.
 -->
<!-- 
I focus my efforts on stock assessment models that can account for biological and technical interactions between species. Trophic interactions are excluded from the investigation because while they are helpful for estimating natural mortality of consumed species (@livingston2000multi-species; @van2015assessing; @latour2003toward) this requires long time series of diet data. Diet data is collected by examining gut contents, which is an inherently `noisy' pursuit (**refs**) and requires significant sampling effort. Such extensions of scientific surveys may not be a practical use of limited scientific and financial resources, as models incorporating trophic interactions are have been shown by simulation testing to be sensitive to inconsistent sampling effort (@van2015assessing). 
 -->

<!--  ## Research Questions

QUESTION: What stocks constrain the profitability of directed species?

QUESTION: What stocks are unable to be assessed by more direct (absolute survey index) approaches with current survey data?

QUESTION: What assemblages of technically interacting stocks, that satisfy the previous 2 questions, exist in the BCIGF and are amenable to the RH method of stock assessment?

QUESTION: What are the bias and precision of estimates of leading stock assessment parameters produced by the RH method of stock assessment?

QUESTION: What are the risks associated with using the RH method of assessment under varying levels of (a) data-quality (b) technical interactions?

QUESTION: What changes need to be made to current survey design and harvest strategy in the BCIGF to minimise the risks of using a management procedure based on the RH method of assessment?

QUESTION: What is the feasibility of a data-based approach to avoiding non-target species in a multi-species fishery?

QUESTION: What are the important predictors for the presence of juvenile Sablefish in commercial catch in the trawl and trap sectors?


Figure 1 shows three possible models of fishery operation and management. Model (a) is the status quo approach of single species stock assessment, where every stock is treated as a separate population (@hilborn1992quantitative). Model (b) keeps the data separate as in model (a), but performs assessments for groups of stocks using statistical models that link the data during estimation (@zhou2010modified; @punt2011among). Finally, model (c) is a total aggregation approach where several species or stocks have their data combined and are then assessed as a single stock (@sugihara1984ecosystems; @gulland1984observed) with TAC set for the aggregate; this is similar to the approach used for assessing Pacific salmon stocks (@english2011fraser). Models (b) and (c) could potentially be used in a data-variable multi-species fishery when model (a) is impractical due to constraints on resources, and may improve the confidence in quantitative results through their statistical properties.

Model (b) is called the Robin Hood approach to stock assessment and requires a novel statistical mode, where model (c) differs from the status quo only by data preparation. Therefore, I focus on a simulation study of the limitations and applications of model (b) for the first two chapters. In Chapter 3 I extend to models (a) and (c) in a risk assessment of data-limited stock assessment methods. Finally, Chapter 4 will identify a multi-species assemblage based on interactions and apply model (b) for assessment.

The following research questions outline my intended path of enquiry: 
 
- Simulate a flatfish complex, different commercial importances == different data availability
    + co-occuring: technical interactions are necessary in the definition of the complex
    + competitive interactions might play into it, in the operating model
    + complex of species, each of which has a complex of stock-area pairs.
- Test bias and precision of possible estimators for model (b) - models (a) and (c) are the same with different data.
    + integrate bias and precision over the entire time series.
- Assess tradeoffs between catch and information when using hierarchical models
    + closed loop simulation
    + economic drivers of fishing effort (same effort -> catch of all three species)
        * competitive externalities?
    + performance under different strategies/tactics
    + Effect of competitive interactions between stocks on carrying capacity of each stock - this could get big
- Risk assessment of each method using closed loop simulation (Ch 3), different harvest control rules based on data availability
    + gradient of data: SS -> HBM -> Total Aggregate
    + Want risk profile associated with data gradient
- Do a stock assessment with an HBM
    + Will need to define complex based on interactions (competitive, or just technical)
 -->
<!-- ***SJ: Still putting together blurbs for these questions - just thinking of something short, the actual chapter descriptions later on can go into more detail***

**1. What are the bias and precision in estimates of stock assessment parameters of interest (depletion, unfished biomass, fishing mortality, catchability, limit reference points) when using method (b) for stock assessment?**

One incarnation of model (b) is called the Robin Hood (RH) approach to stock assessment (@punt2011among). The name comes from its ability to use data-rich stocks to stabilise the assessments of data-poor stocks, which it does by acknowledging the hierarchical structure of multi-species assemblages in the statistical model (Figures 2 and 3). The Robin Hood approach is fairly new (@zhou2010modified; @punt2011among; @kell2012robin) and has been the subject of only one simulation study (@punt2005using) measuring bias and precision. For Chapter 1 of this project I will build an operating model to provide simulated data for an interacting multi-species assemblage under different scenarios and fit a directly linked estimator in a Monte Carlo simulation. The parameter estimates will build distributions of errors between estimated and actual values for leading parameters, allowing for estimates of bias and precision.

**2. What are the benefits and tradeoffs for harvesters and managers associated with assessing assemblages of stocks using the Robin Hood approach for multi-species stock assessment?**

Assessments using the Robin Hood approach could potentially compensate for data-variability in a multi-species fishery. In Chapter 2 I use management strategy evaluation (MSE) to investigate the limits of that compensatory potential, as well as possible ways to exploit it, under a range of economic and social drivers of fishing effort.

**3. What are the risks of using assemblage-based stock assessment methods for data-variable assemblages compared to single species methods, using: a) more detailed data; or b) the data available?**

The three models of fishery management in Figure 1 have differing data requirements. Model (a) assumes that all species are data-rich, while model (b) allows for variability in the data quality between species and model (c) potentially requires the least due to total aggregation benefits. This gradient of data requirements may facilitate a tiered stock assessment policy similar to the ICES Data Limited Stock (DLS) categories (@ices2012implementation), which dictates the conditions under which assemblages should be assessed by each model. Chapter 3 will extend the MSE of Chapter 2 to propose a data requirement policy for multi-species assessments using models (a), (b) and (c) in data-variable fisheries. -->

<!-- 
- Risk profile should remain the same when data decreases - this implies the method should provide more conservative estimates/advice.
- Use the closed loop simulator from chapter 3, testing different HCRs and harvest strategies and tactics
- Define risk as probability $\times$ consequence, (where consequence is lost catch/revenue due to biomass below a limit point ($B_{lim}$)?)

**4. What multi-species assemblages exist on the BC coast that can we define based on biological and technical interactions, using literature, data and local knowledge?**

The Robin Hood approach relies on accounting for interactions in its statistical model. Therfore, any application of the RH approach will require a multi-species assemblage defined according to those same interactions. The coast of British Columbia is home to many species that
 have been fished without a recent stock assessment for some time. In Chapter 4, I'll develop and apply a method to define multi-species assemblages by first considering literature and local knowledge of interactions, then apply a data-based clustering approach.

**5. How do results of stock assessments using methods (a), (b) and (c) differ when applied to an assemblage defined by question 4?**

Once an assemblage is defined, I will apply all 3 methods to obtain 3 assessments of the assemblage. Each method will produce reference point and leading parameter estimates, which may be compared between methods to gain an insight to the effect of model structure on assessment results.

**Benefits:**
Closed loop simulation of an HBM for stock assessment like model (b) could be used for:
    - Management advice
        + Typical use of a stock assessment model
    - Data planning for data-poor stocks/data-variable complexes, and resource limited fisheries
        + Can we focus our sampling effort on a subset of species?
            * Length only for one or two, with full SCA data on the other
 -->

## Statement of Interdisciplinarity

**NEEDS A REWRITE**

Stock assessment of data-variable multi-species fisheries intersects all three pillars of REM. Chapters 1 and 4 draw heavily on applied population ecology in developing and applying a method of stock assessment. Furthermore, chapter 4 will include an explicit consideration of community ecology in identifying multi-species assemblages for the application of model (b) (Figure 1).

In Chapter 2, ecoonomics will be included by considering economic drivers of fishing effort in the management strategy evaluation (MSE) for model (b). These drivers will take into account shifting commercial importance, the cost of fishing and market price of the resource to simulate shifting targets of fishing effort.

In Chapter 3, both policy and economics will be included through a risk management style analysis of the three models in Figure 1. Biological risks to the resource and financial risks to the processing industry reliant upon the resource will be considered in closed loop MSE simulations. This will help identify a prescribed minimum data-quality to uphold the precautionary approach while applying models (a), (b) or (c) to data-variable fisheries.

<!-- # Chapter 1: How can we Determine Species Complexes and Assemblages in a Multi-species Fishery? *Portfolios?* *Explicitly mention BCIGF?*

## Background

Fish stocks are sometimes grouped together into complexes or assemblages for management purposes when data are limited or more conservative management decisions are required (@shotwell2010assessment; @walters2004fisheries; @larkin1972stock). Species *complexes* are collections of species sharing similar life histories or features. A species *assemblage* is defined by the FAO (http://www.fao.org/docrep/003/w4230e/w4230e09.htm) as the term used to describe the collection of species making up any co-occurring community of organisms in a given habitat or fishing ground. Because we'll be using complexes and assemblages for the same purpose - multi-species/multistock stock assessments - herein the terms will be used interchangably.

My intention is to research and apply a method of aggregating stocks in a multi-species fishery into groups. These groups will then be the fundamental base units for the complex-based multi-species stock assessment methods developed in Chapter 2. Because complexes will be the subject of multi-species stock assessments the outcome of the assessments will most likely be affected by how the complexes are formed. In practice complexes are aggregated in several ways. For example, the following approaches to aggregating species into assemblages or complexes are suggested by @gaichas2012assembly: (i) taxonomic affinity (@orr2008species); (ii) habitat preference (pelagic vs. demersal, substrate type), (iii) feeding functional group, (iii) size class; and (iv) combining over all species in a given area. **More refs for these methods.**

- Venn diagram (set theoretical) approach - this shoud probably go in the chapter description.
- @pimm1980food, @cadrin2009accounting


- Intention is to aggregate the 55 stock area combinations in BCIGF into complexes/assemblages.
    + Start with biological information on populations, eg what defines discrete stocks for a species (may be aggregating management areas, eg Dover Sole has two distinct stocks, 3C-D and 5A-E)
    + If discrete stocks are across several mgmt areas, may involve argument about either aggregating to match the scale of the stock, or disaggregating to match the scale of the mgmt unit. (@cope2011reconciling)
    + Disaggregation might be the necessary approach, since biologically distinct stocks that make up a complex might form discrete stocks at different scales (eg. Dover and Rock Sole)
    + Make a Venn style diagram to visually represent discrete stocks for each species, stock area pairs and intersections between stocks. This will define some "potential" complexes.
    + Apply clustering (or similar) approach to catch composition for fisheries/surveys


- Following @cope2011approach, we can perform a k-medoids clustering analysis for clustering ecological distributions. This would require further partitioning to define complexes
    + How to include life histories in this method?
    + Do we want to try a PSA? Seems very subjective and will require a lot of expert input. Not impossible, but time consuming.
- Could also follow @bryan2010assemblages and perform a CCA on species composition - this didn't seem to be very conclusive, though
- Reread @winker2014proof for how his DPC method can be used to identify species complexes/fishing grounds.
- Other clustering methods that may be bent to our task - keep looking:
    + @ono2015marine
- I think there must be some way to cluster species composition as the first step to finding that species co-occur under different circumstances.
    + time
    + space
    + gear/fishery -->

# Chapter 1: Identifying Species in For RH Assessments

## Introduction

- Extending the stock concept to assemblages

QUESTION: What stocks constrain the profitability of directed species?

QUESTION: What stocks are unable to be assessed by more direct (swept-area) approaches?

QUESTION: What groups of technically interacting stocks, that satisfy the previous 2 questions, with similar life histories exist in the BCIGF and are in need of ther RH approach?

## Methods

- Data analysis to discover pinch-point/unassessed species
- Apply a swept-area method
- Risks of swept-area methods
    + varying q levels (time varying q?)
    + varying obs error levels (time varying?)
- Reduce to stocks that require "something more" but lack data/resources for traditional methods
- Data analysis to group stocks based on technical interactions.

## Expected Results



# Chapter 2: Statistical Performance of the RH method

### Background

Model (b) of Figure 1 is quantitatively distinct from models (a) and (c). Specifically, models (a) and (c) are able to use the same quantitative models but differ in data preparation. In contrast, model (b) requires a distinct statistical model in order to link the data of multiple species without aggregation.

Two options exist for allowing multiple species' data to statistically affect each other through the statistical model in a stock assessment (@punt2011among), and both involve penalties applied to the likelihood function. The first involves separately estimating penalties for parameters believed to be shared between species and fitting each model separately with those penalties. However, this approach doesn't directly link the data and is essentially a single species model with some extra homework. The second approach differs from the first by fitting all species in a single hierarchical statistical model, where prior estimates are shared directly between stocks (@gelman2014bayesian Ch 5; @punt2011among).

An estimator where data for multiple species are linked through an hierarchical model has been called the Robin Hood (RH) approach, due to its application in data-variable fisheries (@smith2009reconciling; @punt2011among; @zhou2010modified; @kell2012robin). In the RH approach, an hierarchy is established for parameters which represent or are thought to be affected by biological and technical interactions between species, which we shall call *interaction parameters* (Figure 3). If those species have varying data qualities, the hierarchical approach theoretically allows data rich species to stabilise estimates of interaction parameters in the data-poor species. Indeed, it has been shown that when the RH approach is applied to a data-variable fishery the assessments for the data-rich stocks remain similar while those for data-poor stocks are qualitatively different (@punt2011among; @kell2012robin). The nature of the difference remains unclear, as only one simulation study has been performed for a limited range of interaction parameters. 

QUESTION: What are the bias and precision of estimates of leading stock assessment parameters produced by the RH method of stock assessment?

In this chapter I plan to estimate the bias and precision of both Bayesian (@zhou2010modified) and frequentist (@punt2011among) state space implementations of the RH estimator through simulation modeling. A flatfish complex will be used for the underlying multi-species assemblage. Parameters for multi-species assemblage simulation will be taken from previous flatfish assessments in the BCIGF.

## Methods

Hierarchical estimators will have data supplied by an operating model (OM) that simulates a small multi-species assemblage under exploitation. Interactions between fishes in the assemblage are simulated within the OM as parameters which represent interactions, such as similarities in survey catchability ($q$) or correlated environmental effects on the growth rate ($r$). By using an OM we are able to know the true nature of the data being supplied to an estimator, and therefore are able to assess the estimator's performance. 

There are four main steps to this chapter, outlined below.

1. Code an operating model to produce survey and fishery data.
2. Code estimators to apply to data:
    a. Fully Bayesian State Space (FBSS) model;
    b. Numerically Integrated State Space (NISS) model.
3. Design experimental scenarios which vary parameters representing interactions. 
4. Record MC estimates of bias and precision of each estimator in each scenario to discover boundary conditions for the application of the RH method.

In choosing the structure of the operating model I have two main considerations. The first consideration is how many systems (species and fleets) to include, and the second is the underlying population dynamics. While the ecology, data availability and fishing practices for given systems will determine these two points in practice, in the simulation stage both decisions represent a trade-off of increased model complexity for an increase in information. For example, using a simple biomass dynamics model provides three potential parameters to represent interactions: correlations in growth rate ($r$) due to environment factors; deviations in carrying capacity ($B_0$) from competitive interactions; and catchability ($q$) representing technical interactions. The reduced dimension of the parameter space reduces the breadth of potential sources of interactions in the operating model, but it also increases the possible depth to which the effect of the parameters can be explored.

<!-- 
: while the ecology of a multi-species assemblage will be the major determinant in defining membership in practice, increasing the number of species during simulation may increase model complexity but provide a small marginal benefit in information. The marginal benefit of increasing model complexity will need be an important part of this consideration. 

Second, I will need to decide which population dynamics model to use. The choice of population model will determine sources of interactions and contribute to model complexity (parsimony), again placing a value on information. For example, using a simple biomass dynamics model provides three parameters to represent interactions: growth rate ($r$) correlations due to shared habitat, deviations in carrying capacity ($B_0$) from competitive interactions and catchability ($q$) representing technical interactions. The reduced dimension of the parameter space reduces the breadth of potential sources of interactions in the operating model, but it also increases the possible depth to which the interactions can be explored.
 -->

Two estimators will be tested on the data produced by the operating model, a Bayesian approach (FBSS) and a frequentist approach (NISS). Both estimators will share the same stucture as the OM to avoid confounding structural uncertainty with precision of the estimators. Both estimators are state space models that account for process error in the population dynamics and observation error in the survey indices (@punt2003extending; @de2002fitting). Mathematically both models are specified in the same way: as a penalised likelihood function, with penalties in the Bayesian setting being referred to as prior belief distributions. An example of a penalised likelihood for an assemblage containing $S$ species and penalising deviations of catchability $q$ is
$$
P ( \Theta ~|~ \vec{I_1},\vec{I_2},...,\vec{I_T} ) = \mathcal{L}(\vec{I_1},\vec{I_2},...,\vec{I_T} ~|~ \Theta ) \prod_{s = 1}^S p ( \log~q_s ~|~ M_q, S_q^2 ),~~~~~~~~~~~~~~~~~~~~~ (1)
$$
where $\Theta$ is a vector of parameters, $\vec{I_t}$ are observations (data) for all species at time $t$, $\mathcal{L}$ is the likelihood of the data given some value of the parameters and $p$ is the penalty on log-catchability $\log q_s$ for each species $s \in 1,...,S$, with mean $M_q$ and variance $\S_q^2$. The statistical model in (1) corresponds to an assemblage like the one shown in Figure 2, and is shown as a hierarchical surplus production model in Figure 3.

Both FBSS and NISS models require integration to produce marginal distributions for parameters and likelihoods (@de2002fitting; @gelman2014bayesian; @maunder2015use). Integration generally requires numerical methods due to the non-linear and often non-Gaussian nature of the models, like Markov-Chain Monte Carlo (MCMC) algorithms for distribution sampling. Several options for out of the box MCMC methods exist (ADMB, STAN, JAGS etc **refs**), but depending on the complexity of the model I may require a customised approach for dealing with a high number of latent variables in the model.

- Use TMB for frequentist RE model
- Use ADMB for FBSS model


The model testing will proceed through Monte Carlo trials of experimental scenarios. Parameter estimates from each scenario will be compared to their true values in the OM for estimates of bias and precision. For sensitivity analyses, scenarios will be designed to explore the changes bias and precision caused by changing interactions between species. Possible experiments include time-varying carrying capacity to represent competitive interactions between species (*refs*), testing the limits of data quality and parameter contrast between interacting species, and viewing bias and precision as a function of interaction parameter strengths by varying penalty variances (@gelman2014bayesian, Ch 5.4).

## Expected Results



# Chapter 3: Management performance of the RH method

## Introduction

QUESTION: What are the risks associated with using the RH method of assessment under varying levels of (a) data-quality (b) technical interactions?

QUESTION: What changes need to be made to current survey design and harvest strategy in the BCIGF to minimise the risks of using a management procedure based on the RH method of assessment?

## Methods

- Introduce feedback into the operating model from the previous chapter
    + Show diagram of MSE for MS fisheries
- Run simulations that test
    + data-quality issues
        * value of $q$
        * observation error variance
    + contrast between species
        * level of correlation in time-varying deviances on recruitment/natural mortality
        * similarity in leading model parameters (prior distribution variances)
- Produce contour plots of risk of overfishing (F_t > F_{MSY}) under different conditions of contrast and data-quality issues
- Evaluate current and alternative survey designs and assessment models: 
    + age/length survey frequencies in commercial/survey data.
    + differing assessment models (SP, SCA, SCL) in the same hierarchy

## Results




# Chapter 4: Avoiding non-target species.

## Introduction

- Bycatch is a major problem of fisheries worlwide
    + concrete numbers and references - look at other mscpts for these
    + @dunn2016dynamic
    + 

- Restrictive quotas on several bycatch species, as well as size limits on target species, increasingly constrain multispecies groundfish fisheries in British Columbia (BC).

- Dynamic ocean management (DOM) (@dunn2016dynamic) is a new idea for how to manage in the presence of fine-scale processes (migration, small habitat) driving large scale outcomes (bycatch).
    - Get other references from Dunn
    - relies on fast paced communication, which is becoming a reality

- The BCIGF has 100% coverage ASOP/EM providing a reliable and complete data set
    + Unique, reliable data set in BC
    + 120k records between 1996 and 2010
    + Could be used to forecast hot spots, inform a DOM approach

- We test the feasibility of a quantitative approach to bycatch forecasting using the ASOP data from BC trap and trawl fisheries.
    + machine learning ensemble method
    + test on the presence of juvenile/unmarketable sablefish in commercial catch
    + start with presence/absence, move to catch prediction (classification or regression)
    + As with any forecasting model, predictor selection will be the important part.

QUESTION: What are the important predictors for the presence of juvenile Sablefish in commercial catch in the trawl and trap sectors?

- I will use a combination of cross-validation, sensitivity analyses and modern model selection techniques to test a range of possible predictors
    + normal commercial data
    + environmental data from outside sources
    + Start with presence/absence classification
    + Move on to regression, or at least catch/CPUE prediction in categories.


<!-- We present a method aimed at near real-time forecasting of the spatio-temporal distribution of sub-legal sized (< 55 cm) Sablefish captured in the multispecies groundfish trawl fishery. Forecasts are made via an ensemble machine learning classifier that averages results from Random Forest, Naive Bayes, and Artificial Neural Network classifiers trained on set-by- set catch information and environmental predictors. Human observers have monitored 100% of fishing events in this fishery since 1996, which provide a unique data set to test the feasibility of bycatch forecasting methods. Clas- sifiers trained on commercial data from the long-line trap and trawl fisheries operating in the integrated BC groundfish fishery were tested in 30 replications of a 5-fold cross validation (CV). The CVs produced median presence/absence classifcation rates of 86% for trap data, 78% for trawl data and 76% for combined data sets, outperforming classification based on the modular class in each set. Random Forest outperformed the ensemble in each case, with clas- sification rates of 88% (trap), 83% (trawl) and 84% (combined). Naive Bayes performed most poorly, with error rates consistently higher than the ensemble and occasionally higher than the mode. These results suggest that forecasting of non-target species is feasible given reliable data and the machine-learning tools, but ensemble composition and model selection is paramount. Benefits of accurate forecasts include a potential alternative to quota reduction for stock rebuilding due to decreased regulatory discards, and increased utilisation of di- rected species quota in multi-species fishieres due to avoidance of species with restrictive quotas. -->


## Methods

- Create an ensemble of machine learners
    + Naive Bayes
    + Random Forest
    + Artificial Neural Network

- Test classification of presence/absence of unmarketable sablefish on three sets of commercial data to optimise parameters, choose predictors and test feasibility
    + Three sets: Trap only, Trawl only, Trap and trawl combined
    + Use RF predictor importance to choose most important predictors OR use a lasso based approach
    + Use a k-fold CV to optimise parameters, with the response being error rate (FP + FN)

- If feasible to classify presence/absence, start working on techniques to predict catch
    + May require other machine learners more suited to regression or increase categories from pres/abs to 0/s/m/l
    + Possibly use a "hurdle" regression, that classifies as presence/absence then runs a regression for presence. This removes zeroes (a large subset) from the regression and may take out a skew. In this case, the threshold probability for presence detection will have to be tested. 
    + Not just encounter probability, but distribution of catch size based on a unit of fishing effort (1hr drag, 12 hr soak)
    + Test both CPUE and biomass
    
## Expected Results

- A conclusion on the feasibility of avoidance based on commercial data retained by monitoring.
- Maps of encounter probability for ease of communication to harvesters
- The basis of a fleet communication system for avoidance of non-target species and possible DOM



# Conclusions

This thesis will undertake a study of stock assessment methods for assemblages of multiple interacting species. The focus is on the Robin Hood (RH) method, which contains a hierarchical statistical model linking the data of multiple species. The RH method could prove valuable for data-variable fisheries that are unable to produce stock assessments for all species that they contain. Those species that were previously unable to be assessed could potentially fall inside the stable risk region of the RH method allowing scientifically defensible TACs to be set. This would help some fisheries obtain eco-certification (MSC, Seafood Watch, seaChoice), helping to improve biological sustainability of market share.

Further to contributions to the field of fisheries science, this thesis also satisfies the interdisciplinary spirit of REM in two chapters. First, assessing multiple species simultaneously using the RH approach brings possible advantages, such as an efficient allocation of survey resources. Such advantages are to be tested in Chapter 2 through management strategy evaluation, synthesising ecological drivers of population dynamics and economic drivers of fishing effort. The other methods - single species (SS) and total aggregation (TA) - are analysed as alternatives to the RH method in a risk assessment in Chapter 3. The risk assessment is intended to recommend data-requirements and harvest control rules for stable social and biological risk, synthesising economics, ecology and policy.

Efficient allocation of resources is therefore an important part of the sustainable management of multi-species fisheries. This para needs refs, better ideas and structure. Does it even go here? Maybe combine it with the following paragraph on multi-species assessments. Also, include information here about good enough mechanisms for resource distribution
   SARA, PA state that at a given level of biological risk, a recovery process has to be implemented.
   Are expensive, model based assessments required for every species?
   What constitutes good enough management?
   There are two parts to resource allocation
1.  Identification of need - pinch-point species are an externality on directed species
2.  Mechanisms for resource distribution - good enough MPs: Swept-area, total Agg, RH
   A paralysis of choice is common in situations like this.

## Resource allocation improvement (taken from intro)

I propose a practical, stake-holder driven management approach that seeks to to satisfy conservation concerns while increasing economic welfare in multi-species fisheries. Assessment techniques should be *practical* in that they achieve conservation and management goals efficiently, such as reserving the most technologically advanced and resource intensive management procedures for those stocks that absolutely need it. Management decisions should be *stake-holder driven*, where priority is given to actions that increase the economic welfare of the fishery. This will allow for positive economic feedback and increase the pool of resources available for future management of the fishery. The goal of a practical, stake-holder driven management approach is to simultaneously improve the sustainability (intergenerational equity) and profitability of multi-species fisheries.

# Biblography


<!-- # Chapter 1: Bias and Precision in Nottingham Forest.

**Guiding question:**

**1. What are the bias and precision in estimates of stock assessment parameters of interest (depletion, unfished biomass, fishing mortality, catchability, etc.) from the estimator in model (b)?**

## Background

Model (b) of Figure 1 is quantitatively distinct from models (a) and (c). Specifically, models (a) and (c) are able to use the same quantitative models and differ only in how the data is prepared and how the TAC is set. In contrast, model (b) requires a distinct statistical model in order to link the data of multiple species without aggregation.

Two options exist for allowing multiple species' data to statistically affect each other through the statistical model in a stock assessment (@punt2011among), and both involve penalties applied to the likelihood function. The first involves separately estimating penalties for parameters believed to be shared between species and fitting each model separately with those penalties. However, this approach doesn't directly link the data and is essentially a single species model with some extra homework. The second approach differs from the first by fitting all species in a single hierarchical statistical model, where prior estimates are shared directly between stocks (@gelman2014bayesian Ch 5; @punt2011among).

An estimator where data for multiple species are linked through an hierarchical model has been called the Robin Hood (RH) approach, due to its application in data-variable fisheries (@smith2009reconciling; @punt2011among; @zhou2010modified; @kell2012robin). In the RH approach, an hierarchy is established for parameters which represent or are thought to be affected by biological and technical interactions between species, which we shall call *interaction parameters* (Figure 3). If those species have varying data qualities, the hierarchical approach theoretically allows data rich species to stabilise estimates of interaction parameters in the data-poor species. Indeed, it has been shown that when the RH approach is applied to a data-variable fishery the assessments for the data-rich stocks remain similar while those for data-poor stocks are qualitatively different (@punt2011among; @kell2012robin). The nature of the difference remains unclear, as only one simulation study has been performed for a limited range of interaction parameters. In this chapter I plan to estimate the bias and precision of both Bayesian (@zhou2010modified) and frequentist (@punt2011among) state space implementations of the RH estimator through simulation modeling.

## Method

Hierarchical estimators will have data supplied by an operating model (OM) that simulates a small multi-species assemblage under exploitation. Interactions between fishes in the assemblage are simulated within the OM as parameters which represent interactions, such as similarities in survey catchability ($q$) or correlated environmental effects on the growth rate ($r$). By using an OM we are able to know the true nature of the data being supplied to an estimator, and therefore are able to assess the estimator's performance. 

There are four main steps to this chapter, outlined below.

1. Code an operating model to produce survey and fishery data.
2. Code estimators to apply to data:
    a. Fully Bayesian State Space (FBSS) model;
    b. Numerically Integrated State Space (NISS) model.
3. Design experimental scenarios which vary parameters representing interactions. 
4. Record MC estimates of bias and precision of each estimator in each scenario to discover boundary conditions for the application of the RH method.

In choosing the structure of the operating model I have two main considerations. The first consideration is how many systems (species and fleets) to include, and the second is the underlying population dynamics. While the ecology, data availability and fishing practices for given systems will determine these two points in practice, in the simulation stage both decisions represent a trade-off of increased model complexity for an increase in information. For example, using a simple biomass dynamics model provides three potential parameters to represent interactions: correlations in growth rate ($r$) due to environment factors; deviations in carrying capacity ($B_0$) from competitive interactions; and catchability ($q$) representing technical interactions. The reduced dimension of the parameter space reduces the breadth of potential sources of interactions in the operating model, but it also increases the possible depth to which the effect of the parameters can be explored.


: while the ecology of a multi-species assemblage will be the major determinant in defining membership in practice, increasing the number of species during simulation may increase model complexity but provide a small marginal benefit in information. The marginal benefit of increasing model complexity will need be an important part of this consideration. 

Second, I will need to decide which population dynamics model to use. The choice of population model will determine sources of interactions and contribute to model complexity (parsimony), again placing a value on information. For example, using a simple biomass dynamics model provides three parameters to represent interactions: growth rate ($r$) correlations due to shared habitat, deviations in carrying capacity ($B_0$) from competitive interactions and catchability ($q$) representing technical interactions. The reduced dimension of the parameter space reduces the breadth of potential sources of interactions in the operating model, but it also increases the possible depth to which the interactions can be explored.


Two estimators will be tested on the data produced by the operating model, a Bayesian approach (FBSS) and a frequentist approach (NISS). Both estimators will share the same stucture as the OM to avoid confounding structural uncertainty with precision of the estimators. Both estimators are state space models that account for process error in the population dynamics and observation error in the survey indices (@punt2003extending; @de2002fitting). Mathematically both models are specified in the same way: as a penalised likelihood function, with penalties in the Bayesian setting being referred to as prior belief distributions. An example of a penalised likelihood for an assemblage containing $S$ species and penalising deviations of catchability $q$ is
$$
P ( \Theta ~|~ \vec{I_1},\vec{I_2},...,\vec{I_T} ) = \mathcal{L}(\vec{I_1},\vec{I_2},...,\vec{I_T} ~|~ \Theta ) \prod_{s = 1}^S p ( \log~q_s ~|~ M_q, S_q^2 ),~~~~~~~~~~~~~~~~~~~~~ (1)
$$
where $\Theta$ is a vector of parameters, $\vec{I_t}$ are observations (data) for all species at time $t$, $\mathcal{L}$ is the likelihood of the data given some value of the parameters and $p$ is the penalty on log-catchability $\log q_s$ for each species $s \in 1,...,S$, with mean $M_q$ and variance $\S_q^2$. The statistical model in (1) corresponds to an assemblage like the one shown in Figure 2, and is shown as a hierarchical surplus production model in Figure 3.

Both FBSS and NISS models require integration to produce marginal distributions for parameters and likelihoods (@de2002fitting; @gelman2014bayesian; @maunder2015use). Integration generally requires numerical methods due to the non-linear and often non-Gaussian nature of the models, like Markov-Chain Monte Carlo (MCMC) algorithms for distribution sampling. Several options for out of the box MCMC methods exist (ADMB, STAN, JAGS etc **refs**), but depending on the complexity of the model I may require a customised approach for dealing with a high number of latent variables in the model.

The model testing will proceed through Monte Carlo trials of experimental scenarios. Parameter estimates from each scenario will be compared to their true values in the OM for estimates of bias and precision. For sensitivity analyses, scenarios will be designed to explore the changes bias and precision caused by changing interactions between species. Possible experiments include time-varying carrying capacity to represent competitive interactions between species (*refs*), testing the limits of data quality and parameter contrast between interacting species, and viewing bias and precision as a function of interaction parameter strengths by varying penalty variances (@gelman2014bayesian, Ch 5.4).


<!-- The main difference between the FBSS and NISS estimators is in how inferences are made (@maunder2015use). Inferences for both are extended from marginal and conditional distributions produced by integrating over nuisance parameters. In the NISS model the likelihood function is integrated over the process error noise and penalties to produce a marginal likelihood (@de2002fitting; @punt2003extending), which is then used to infer maximum likelihood estimates and standard errors of leading parameters. In the Bayesian model integration is over the full parameter space (@gelman2014bayesian) and marginal and conditional distributions for all leading and derived parameters are produced, which are themselves inferences of the FBSS model. 
 -->
<!-- 
* challenges of each
    - numerics
    - MCMC - will this require an out of the box method, or something more customised given the hierarchical nature of the problem (many parameters - some with little covariance - large jumping distributions)
 -->


<!-- + Fix variance hyperparameters on shared priors/penalties on REs and vary in $(0,\infty)$, varying the allowed strength of the linkage between member species. This can produce plots of bias/precision of parameters which possibly vary with the linkage strength. (@gelman2014bayesian Ch 5)
    + Some experimental design will be needed to find most efficient path through the parameter space

    

- Partially follow @gelman2014bayesian Chapter 5 for parts of the analysis.


## Expected Results

The main product of this chapter will be distributional estimates of bias and precision for leading parameters produced by the RH given an underlying configuration of population dynamics and multi-species community. This will improve understanding of the RH method for stock assessment, and the limits to the application of such a tool. Results will then be published in an article in a peer reviewed scientific journal.



# Chapter 2: Management Strategy Evaluation: How Much can Robin Hood Take From the Rich?

## Background

**Guiding question:** 

**2. What are the benefits and trade-offs for harvesters and managers associated with using the Robin Hood approach for stock assessment?**

Biased stock assessment models are commonplace in fisheries management. For example, errors-in-variables models are well known to be asymptotically biased (@de2005state) but are still applied in fisheries stock assessment (@punt2003extending). Sometimes, bias can be explicitly corrected for by the manager, or implicitly by a harvest control rule which implements a harvest strategy (*refs?*). *Harvest strategies* are the way in which managers control the output (harvest) of the fishery, and could be either controls on effort (input controls) or controls on catch (output controls) (@hilborn1992quantitative, Ch. 15). Testing of harvest strategies in conjunction with assessment methods is done via closed loop simulation in a Management Strategy Evaluation (MSE) (@de-la-Mare1998Tidier-fisherie; @sainsbury2000design). Figure 4 shows a conceptual model of the MSE framework for a multi-species fishery.

In this chapter I will run a MSE on the Robin Hood approach to stock assessment. Because the goal of the RH method is to supply scientifically defensible TACs for data-variable multi-species fisheries, I intend to test output control harvest strategies in the form of feedback Harvest Control Rules (HCRs). Further to the HCR there are three multi-species specific management strategies I wish to evaluate in this chapter, outlined below:

1. Allocation of survey effort: For example, is it possible to exploit species interactions and focus full scientific sampling on one, low variance (commercially important) species in an assemblage, and only sample the other lower importance species for length, say? Does the RH method change the value of information gained from surveying a species?
2. Distribution of fishing effort: In a multi-species fishery, market prices will affect targeting of fishing effort between interacting species (@clark2010mathematical, Ch. 3). How robust is the RH method to changing effort allocation between species based on market forces?
3. Multi-species management: Managing for different species productivity levels when fishes interact can be tricky (@dichmont2006management2) and lead to overfishing of one or more species in an assemblage. The RH method may be able to help identify these situations, allowing managers to plan input controls to mitigate effects.

## Methods

The methods for this chapter follow the following 4 steps:

1. Expand OM to include feedback from an estimator.
2. Experimental design of management strategies and OM changes for each:
    i.   Allocation of survey effort in a data-variable fishery.
    ii.  Economically driven fishing effort.
    iii. Multi-species management.
3. Run MSE for each scenario to assess limits, trade-offs and applications of the RH model of stock assessment.

Step 1 will expand the operating model and estimator into a MSE framework by defining a decision rule which implements a harvest strategy (@hilborn1992quantitative, Ch. 15). As a starting point, the harvest strategy will be based on the guidelines given by DFO (@DFO2006A-Harvest-Strat). When the stock assessment model provides an abundance estimate, the harvest strategy will inform the operating model of TAC for the following year. This will provide a general closed loop simulator able to test several management scenarios.

In step 2, management scenario experiments will be designed to test the guiding question, uncovering benefits and trade-offs for harvesters and managers. Testing different scenarios will require the modification of the OM and the estimator structure to change how catch, effort and surveys are simulated. Strategy i. differs survey designs across species in an assemblage, which may imply a different population dynamics model for each species in the estimator. In strategy ii. havesters will change their targeting behaviour towards the resource that provides the highest profit, requiring calculation of optimal control rules based on fishing costs and market prices in the operating model. Finally, strategy iii. will require a way to fish multiple resources with a single effort, possibly through a time-varying fishery dependent catchability $q$ for each species. 

Finally, many replications of each strategy under a range of scenarios (parameter values) will be tested under closed loop simulation (Figure 4). Furthermore, using the same framework it would be possible to test combinations of strategies i - iii to see how they interact, such as shifting market prices driving survey effort.

<!-- - Experimental design of scenarios to test problems/applications in background
    + Different HCRs and how to implement them (strategies and tactics (@hilborn1992quantitative))
        * bycatch requirements
        * size limits
        * gear controls
    + Value of information (@walters1978ecological; @walters1986adaptive)
        + Tests of Adaptive management scenarios for implementing data-variable management?
    + Different ways to simulate catch
        * Single effort, different fishery dependent $q$ (how do we vary $q$?)
        * Economically driven effort (fake market forces), outlined further below
        * Parametrically
        * based on historical data
- Economically defined effort based on market forces (@clark2010mathematical Ch2; further refs)
    + requires data on market forces (probably simulated for fake stocks - if only two stocks are used, then a just change between them along a gradient, add noise)
    + This will change targeting behaviour: 
        * is it best to do this through a single effort E_t and time varying q?
        * or have a total effort for all species, with a share for each defined by the optimal control?
    + *Dynamic optimisation*
    + *Ideal free distributions* pushing harvesters between resources (species), instead of between spatial patches (a la Okamoto et al)

## Expected Results

I expect to quantify the performance of the RH method of assessment as a management tool for setting TACs under a range of conditions. In strategy i. the limits to how much the RH method can "steal" from the rich species to enable assessments of poor species will be determined. In strategy ii. I expect to discover the robustness of the RH method to shifting targeting behaviour based on dynamic economic conditions. Finally, in strategy iii. I expect to discover applications of the RH approach in simultaneously managing multiple resources under financial limitations. I expect to report these results in 2 publications, one for multi-species management (i. & iii.) and one for the effects of economic changes on targeting in a data-variable fishery.


# Chapter 3: A Risk Analysis of Multi-Species Stock Assessment Policy.

**Guiding Question:**

**3. What are the risks of using assemblage-based stock assessment methods for data-variable assemblages compared to single species methods, using: a) more detailed data; or b) the data available?**

***This chapter needs more references. SJ to ask MR and mine Marine Policy journal***

## Background

Management of renewable resources in the presence of uncertainty inherently involves risk. One prominent issue for fisheries is overfishing, the risk of which increases as data quality decreases (ref). Ideally, catch advice provided by assessment methods should become more conservative as data quality decreases (@hilborn2001precautionary; @DFO2006A-Harvest-Strat), in order to stabilise the biological risk of overfishing in the absence of good data. Indeed, data-limited single species methods for stock assessment and management are currently being developed and tested for their ability to detect and avoid overfishing (@maccall2009depletion; @ICES2013Report-of-the-W; @Carruthers2014Evaluating).

In this chapter, I view single species (SS), Robin Hood (RH) and total aggregation (TA) methods (Figure 1) as lying along a gradient of data-quality for a data-variable fishery (Figure 5). The aim of this chapter is to quantify the range of data-quality and harvest control rules required for each method to perform within an acceptable level of risk. These ranges I will call *stable risk regions* for each method. A conceptual model of stable risk regions for the three models is shown in Figure 5.

I will test both biological risks of overfishing and social risks of fishery closures (@hilborn2001precautionary), attempting to find a balance between social needs and resource conservation. It is my hope that these stable risk regions can be used to inform and propose a fictional tiered stock assessment policy prescribing data-requirements for the application of the three methods within a data-variable fishery.

## Methods

I will use an MSE approach to quantify the boundaries of stable-risk regions for each method. The stable risk regions will then inform a fictional policy about conditions in which to use each method in a data-variable fishery. This would require an inclusion of the interests of human-capital reliant on the resource, such as harvesters and processors, and identification of trade-offs between intergenerational equity and present income for those sectors (@hilborn2001precautionary), tested under a range of conditions. This chapter will involve the following 4 steps:

1. Identify the gradient (path) through data availability and HCR conservatism for a data-variable fishery.
2. Include human-based capital needs, extending the economic driver OM from the previous chapter.
3. Identify limit reference points (LRPs) and human-biological trade-off decision rules.
3. At a "grid" of data-availabilities and HCRs, apply a MSE for each method and record biological and social risks - probability of dropping below LRPs with a consequence of lost welfare to industry reliant on the resource.


<!-- - Identify a gradient of data-availabilty to be followed for the experiments
    - based on the contrast between stocks and availability of sampling data
    - Might have to restrict scope to avoid combinatorial explosions
        + Gradient through biomass data (dropping resolution in age/length data etc)
        + Gradient through contrasts between species (obs error contrasts, differences in sampling resolution (some age vs all age))
- For each point along the gradient, apply all three methods of assessment and record the probability of dipping below $0.2 \cdot B_0$ for each stock 
    - this will require some way of combining the probabilities
        + Just the overall probability of *some stock* being overfished
        + Or a more sophisticated weighting system, based on importance
    - Will require determining HCRs for each method
- Based on these results, find the points along the gradient at which we should switch assessment methods can be estimated
- Analysis will be MSE style approach (extension of previous chapter)
- Inform a policy based on these points.
- Should we add further tiers?
    + Empirical methods
    + accounting for bad experimental design?

## Expected Results

I expect to quantify stable risk regions of data-quality and catch conservatism for each method, balancing the biological risk to the resource and social risk to industry. This will help produce a recommended tiered stock assessment policy prescribing the application of the SS, RH and TA methods. The recommended policy and stable risk regions will be published in a peer reviewed journal, such as Marine Policy.

# Chapter 4: An Extension to Real Fisheries Data.

**Guiding Questions:**

**4. What multi-species assemblages exist on the BC coast that can be defined based on biological and technical interactions using literature, data and local knowledge?**

**5. How do results of stock assessments using methods (a), (b) and (c) differ when applied to an assemblage defined by question 4?**

## Background

There are few applications of the RH method in the literature (@smith2009reconciling; @zhou2010modified; @punt2011among; @kell2012robin). Those which do exist provide limited justification for the assemblages they use. Because the RH method could provide a benefit to data-variable fishery management, definition of assemblages for the application of the RH method should account for biological and technical interactions reflected in the hierarchical estimator. 

In this chapter, I will develop a method which uses scientific literature on the ecology of species, local knowledge of species interactions and fishery and scientific data to identify assemblages which are good candidates for the RH approach. I will then apply the RH method to produce estimates of leading stock assessment parameters and a recommendation on TAC for at least one of these assemblages.


### Methods

My study system will be the British Columbia Integrated Groundfish Fishery (BCIGF) (@PRIFMP2015). The BCIGF is a data-variable fishery that sets quota for 55 different stocks (defined as species-area combinations). Of those 55 stocks, 41 received the a red or yellow rating on impacts to the target stock by Seafood Watch (@Driscoll2014Groundfish-comp), quoting that a lack of up-to-date information was available. The RH approach to stock assessment could be used for assessing those stocks in the BCIGF which lack assessments under the SS approach.

Some methods of assemblage identification are put forward in the literature (@bryan2010assemblages; @gaichas2012assembly), with varying degrees of success at dividing the community into cliques of species. According to @gaichas2012assembly the membership of an assemblage largely depends on objectives, which is very similar to the observations of @secor2013unit in the definition of a unit stock. My objectives are to define an assemblage based on technical and biological interactions, specifically those represented by shared priors in the RH method of stock assessment. Essentially, I'm attempting to extend the concept of stock to a multi-species assemblage.

By reviewing scientific literature and drawing on local knowledge I plan to scope the space of possibilities for assemblages of interacting species in the BCIGF. This will require:

1. Fully articulated objectives for the assemblage, such as data-availability for each species, and level of shared or evolutionary life history;
2. Identification of interactions important to the definition, and if and how these interactions are represented in data, scientific literature or through local knowlege of resource users.

Once the space of possibilities is scoped I will apply unsupervised clustering techniques (@bryan2010assemblages; @olden2008machine) to cluster species based on interactions represented in catch and survey data, producing candidates for multi-species assemblages. These assemblages will then form the management unit for the RH method of assessment. Unit-assemblages will then be assessed using all three methods of Figure 1. For the RH method, I expect the model to include three layers of hierarchy:

1. Single stock-area combination likelihood functions;
2. Multiple stock-area combinations sharing priors within a species;
3. Multiple species sharing hyper-priors within an assemblage.

The results of each method will then be compared to gain insight into the effects of model structure on assessment of the same data.

<!-- 
- Few applications of the RH method in practice (@punt2011among; @zhou2010modified; @kell2012robin; @smith2009reconciling)
- It remains to be seen 
    - how the method as analysed up tile now stands up in a real setting 
    - whether we can identify suitable assemblages for application of RH method (or the other 2 - total aggregation requires some assumptions on shared LH)
- Some methods of identifying assemblages have been used in the past (@gaichas2012assembly; @bryan2010assemblages), with varying degrees of success.
    + Need to fully articulate objectives to reduce the space of possible assemblages: this may require a bound on the size of assemblage, or smart reduction on candidate members.
    + what interactions are important, how are they represented in the data?
    + Are there interactions/assemblages that are known about (local knowledge, literature) that do not appear in the commercial/survey data?
    + Can we extend the stock concept to a multi-species assemblage, and under what conditions can we do so?
- Given an assemblage defined by biological and technical interactions, constructed by reviewing DLLK (Data, Literature and Local Knowledge) perform a stock assessment. -->

<!-- ## Methods

- Choose a study system (probably the BCIGF)
- Review literature, collect local knowledge, narrow down possibilities based on ecology.
- Use data-based methods (ML) to cluster species based on interactions (technical)
    + commercial data, 
    + survey data or 
    + both
- Combine narrowed field from LLK with clustered data to (hopefully) produce assemblages
- Assess using RH approach
    + Hierarchically assess multiple species, each with multiple stocks (determined by statistical area)


## Expected Results
The definition of multi-species assemblages depends largely on objectives. Because of this, I don't expect to produce an infallible tool for identifying assemblages of interacting species, but instead a procedure to follow. The procedure will include literature review, scoping of alternatives according to objectives and cluster analysis of data. Unfortunately, some subjectivity and convenience is probably inherent in the process. Assessments performed in candidate assemblages will provide scientifically defensible TACs, recommended to the BCIGF. I expect this will result in 2 publications: 1 for assemblage identification, and one for the comparison of assessment results.

 -->


<!-- Uncertainty in assessments can arise from the data collection process, with sources including the mis-reporting of fishery-dependent removals, inappropriate experimental design and incorrect survey data standardisation. Moreover, survey data time series are ideally sufficiently long to capture contrast in the abundance trends of a stock (@ICES2012Report-on-the-C). However, most stocks exhibit one-way-trips from high to low abundance (@hilborn1992quantitative) or suffer from low commercial importance and lack appropriately designed surveys.



Catch data and indices of abundance are subject to two sources of uncertainty: quality of data and security of the data-stream. The quality of the data could be jeopardised by misreporting of catch and other fishery dependent mortality and inappropriate experimental design of surveys. The security of the data stream is affected by the resources required to collect and store survey and fishery dependent data required for assessments.
 -->
<!-- - Challenges in setting TACs for individual species
    + TACs require:
        * estimates of abundance
        * estimates of productivity ($r$ in a SPM)
        * harvest rate/limit reference points
        * harvest strategy
    + Estimates of abundance, productivity and limit reference points require assessments
    + Assessments require data
        + data-limited/data-poor stocks
        + (inappropriate) survey design -  standardised indices of abundance
        + (long) time series of data - doesn't always exist
    - @hilborn1992quantitative: errors in the reliability of TACs can arise from each element involved.
- How many assessments are typically needed?
    + long time series of data points for making stronger inferences
    + enough time to be sure of contrast in the time series of IoA data - preferably including points above and below MSY and a period of increasing abundance. Typically, the data available are "one way trips"
    + NERC (http://www3.imperial.ac.uk/cpb/databases/gpdd/data) recommends time series covering ten generations - not always possible. In practice, the more the better, so start collecting data now.
- Scientific and resource needs for doing each assessment?
    + index of abundance data
        * surveys (boats, manpower)
        * experimental design (science advice)
    + catch data
        * unbiased reporting (ASOP/EM)
        * many sources to check - what about discard mortality and ghost fishing?
- Consequences of not doing assessments?
    + Stocks can become overfished without knowledge of their state in response to fishing efforts, leading to (economic) extinction
    + Example: Yelloweye -->

<!-- 
In order for harvesters to retain the catch, quota must be distributed to harvesters or made available for purchase. Quota requires that a Total Allowable Catch (TAC) is set for each stock, and setting a scientifically defensible TAC requires some form of stock assessment. 
-->

<!-- 
This leads to our motivating research question: **How do we perform annual stock assessments for every species in a multi-species fishery?**

One answer to the above question is to design new surveys to collect enough data over several years that can then be used in the existing single species stock assessment approach for every stock. In a realm of unlimited scientific funding and support this approach might be possible, but resources are typically limited and competition for them is a zero-sum game. I prefer to think in reverse of this and loosely follow the example of Pacific salmon, by simultaneously assessing aggregate groups of stocks we call *assemblages*. Where we stray from the example of salmon is in the composition of assemblages: I consider assemblages that include multiple species based on technical and fishery interactions between and among stocks. This brings up the question of how to define such an assemblage, which starts with the stock concept (@cadrin2013stock).

As outlined above, a typical fishery is usually managed from a single species perspective where species are assumed to be composed of one or more `unit stocks'. The *unit stock* is a concept that varies based on management objectives, and arose from the need to define discrete groups of fish as the subjects of population dynamics models (@secor2013unit), and can be traced as far back as the observations of @hjort1914fluctuations on herring migrations. The discretisation of fish populatios arose from an effort to understand how fishing and other external forces influence the internal dynamics of groups of fish. The origin of the concept has led to the unit stock having several distinct but overlapping definitions (@begg1999stock; @booke1981conundrum; @booke1999stock; @larkin1972stock), all of which are practically synonymous with a biological population and often characterised by reproductive isolation and shared life history parameters (@secor2013unit).

Some authors recommend the Evolutionarily Significant Unit (ESU) as the fundamental unit, as managing for this will preserve genetic diversity inherent in locally adapted sub-populations (*Reference Sinclair 1988*). However, defining ESUs is often impossible to do directly, as assessing genetic fitness is a difficult task. Instead, several proxies are often used in a holistic way to define stocks (@dizon1992rethinking; @begg1999stock). Recently, it has been argued that demographic independence is in fact more important than genetic independence (@benson2011evaluation) allowing for a small level of reproductive exchange between stocks (around 5 - 10%). In practice the unit stock is often operationally defined: @secor2013unit argues that due to the external forcing of fishing "... that stocks cannot be conceived exclusively as biological populations."

**What is the `fundamental management unit' in a multi-species fishery?**

Single stock management in a multistock context has been shown to lead to suboptimal yields and sometimes the extermination of weaker stocks (@ricker1958maximum; @ricker1973two). Similarly, the single species approach to management in multi-species fisheries may also lead to suboptimal conditions (@sugihara1984ecosystems; @gulland1984observed). @walters2005possible argue that "... widespread application of single species Maximum Sustained Yield (MSY) policies would in general cause severe deterioration in ecosystem structure..." due to adverse effects of fishing on food web dynamics. Furthermore, @mueter2006using cautions against using a sum of single species MSYs as a proxy for the MSY of a multi-species complex because of ecological interactions and fishery impacts.

As fisheries rationalise and move from multi-single-target fisheries (many separate fleets fishing targeted stocks) to single-multi-target fisheries (single multi-purpose fleet fishing several stocks) (@gulland1984observed), single species management becomes less appropriate because human disturbances are not applied to a single species. @secor2013unit describes the concept of a stock being flexible, sometimes ranging from a species to a brood. I ask the question of whether this can be extended to assemblages of species under the right conditions.

In extending the management unit of a fishery to assemblages, there must be a common element to bring the species together. In Chapter 1, we consider defining this common element as technical and fishery interactions and manage species in groups, similar to @pauly1979theory or the aggregate management approach suggested by @sugihara1984ecosystems or warned against by @paine1984some. My enquiry differs from these examples in two ways. First, I include fishery interactions as part of the definition of the groupings. Second, I will not be aggregating the biomass of groups and averaging parameters across species, one of the main complaints of @paine1984some; my alternative method is discussed below. 

**How do we perform assemblage-based stock assessments in a multi-species fishery?**

We propose the development of multi-species stock assessment methods that share information between species in the same assemblage by taking biological and fishery interactions into account. Such methods could be invaluable in multi-species fisheries where some stocks have too little data to support conventional stock assessments. Stocks for which conventional assessments are not possible with existing data-streams are termed *data-limited* (@ices2012implementation) and typically correspond to lower value or bycatch species in data-variable multi-species fisheries; we call a multi-species fishery *data-variable* when it harvests stocks that are data-limited and stocks that are not. An example of a *data-variable* fishery is the British Columbia Integrated Groundfish Fishery (BCIGF) that operates multiple gear types within 55 stock-area combinations across 9 management units (@PRIFMP2015). High value species in the BCIGF (halibut, sablefish) have dedicated surveys and regular stock assessments to set TAC annually, while lower value and bycatch species (yelloweye rockfish) are fished under quota limits set either using out of date assessments or assessments informed by dubious data.



**What models allow the sharing of information between stocks for assemblage-based stock assessments?**

Two main options have been developed for allowing data from multiple stocks to influence the stock assessments of one another (@punt2011among), both as ways to implement the statistical model. First by using prior/penalty distributions on parameters and fitting models one at a time (**refs!!**), or second by fitting models for each stock simultaneously in a single estimator (**refs!!**). The first method amounts to fitting multiple separate single species assessments so we choose not to take that approach. The second method can be considered as a Hierarchical Bayesian Model (HBM) (@gelman2014bayesian), where prior distributions on some parameters are shared among stocks (@punt2011among; @zhou2010modified). This approach has only recently been extended from subpopulations of single stocks (@zhou2010modified) to multiple species (@punt2011among) for the purposes of sharing information in a data-variable multi-species fishery.
 -->
<!-- We investigate the application of a hierarchical bayesian model

For subpopulations of the same species life history parameters can be shared through a hierarchical approach (**refs**), but for different species this is obviously not a scientifically sound approach. **I'm starting to get away from literature based exposition here (and in the prev paragraph), so I'm going to leave this until I read more on the RH approach. Notes for this paragraph are below:**

- Technical and fishery interactions may have effects on:
    + Fishing mortality trends in an area (@punt2011among)
    + selectivity at length (@punt2011among)
    + Catchability (@zhou2010modified)
    + length-at-age (depending on the complex)
    + recruitment deviations due to environmental effects (@punt2011among)
so these are all possible points where information could be shared. ***Really depends on the groupings we're running stock assessments on.***
- ~~Could we consider running different models simultaneously, a surplus production model for a data-poor stock fit in a hierarchy with SCA models for data-rich stocks?~~ -->

<!-- To overcome inherent uncertainty stock assessments require long time series of data which satisfy strong assumptions about how that data is collected. This requirement of rigour in the data collection process makes stock assessment a complex task, even for the most well managed fisheries.

Eco-certification groups such as the Marine Stewardship Council, Sea Choice and Seafood Watch *footnotes for each of these* allow consumers to place direct market pressure on fisheries (@Pelc201556). Fisheries that don't perform regular stock assessments either remain uncertified or receive poor sustainability ratings (@Driscoll2014Groundfish-comp). Seafood products and fisheries are rated based on three main criteria: (i) sustainability of target stock exploitation; (ii) impacts of fishing on the ecosystem, including other species; and (iii) effective fishery management. Criteria (i) and (iii) are dependent on regular assessments of stock abundance in any fishery. Criterion (ii) is dependent on regular stock assessments in a multi-species fishery where several species are caught in the same fishing event.
 -->




<!-- **What stock assemblages exist in a multi-species fishery?**



**How can information be shared between stocks in the same complex for stock assessments?**

The method of information sharing we will investigate is a hierarchical Bayesian state space method of stock assessment (@zhou2010modified). Where we differ from the method used by @zhou2010modified is the detail level in the population dynamics model: they use a surplus production model which is appropriate for their short-lived study system; we intend to test statistical catch at age and catch at length models, which reflects more accurately the nature of our motivating system. Furthermore, a more detailed model may provide more opportunities for a transfer of information between species and extend the efficacy of the approach. For example, catchability and selectivity may be related through fishery dynamics in the complex and steepness may be able to be shared between biological complexes; estimates of length-age distributions might also benefit from such an approach, increasing confidence in catch-at-length stock assessment methods. --> 


<!-- Because the proposed complex-based stock assessment method is a data-limited approach, it is important to perform a risk assessment of the method. To balance the chance of increased bias in stock estimates from lower resolution data, management decisions must necessarily become more conservative as the detail level of data decreases. Conservative management decisions in simulation amount to harvest control rules which set lower TACs for data limited stocks. Conservative harvest control rules in combination with data-limited methods have been tested in previous studies (@Carruthers2014Evaluating; @ices2012implementation) and have been found to increase risk in some cases where the stock is already overfished.

Management strategy evaluation is the standard method for testing stock assessment models (@smith1999implementing) and will be used to test any candidate multi-species models that are developed. MSE works by running closed loop simulations of population dynamics with process error in an operating model. The operating model provides observations with error to a stock assessment process, the results of which inform the decisions of a simulated manager who implements a harvest control rule and in turn affects the next time step of the simulation. Operating models are designed to test the robustness of a stock assessment by varying key simulation parameters and the structure of the dynamics. Stock assessment model fits and estimates of management parameters such as depletion and unfished abundance are then compared to the simulated values as a way of measuring performance.

In a multi-species context the MSE would test our complex based models in the same way as for single species models, as well as by varying the parameters representing interactions and contrasts between stocks in the complex. Scenarios simulated by an operating model include changing effort dynamics, bycatch requirements, gear dynamics and time-area closures. Scenarios can be simulated based on raw data from at sea observer programmes or from parametric distributions. Different scenarios will help test the limits of the stock assessment method, identify tradeoffs between management objectives and quantify the risks associated with using the proposed stock assessment method. -->
 
<!-- 
Chapter 1 draft methods:
- A simulation model of a small (flatfish) complex, three species made up of several stocks (corresponding to management areas) with similar life histories:
    - One high value, well studied stock
        + length, age, selectivity info
        + fishery indep catch, effort, low variance indices
        + good estimates on q
    - one intermediate value stock
        + some age data, good length data
        + fishery indep catch/effort, med var indices
        + estimates on q
    - one low value stock, mostly bycatch
        + no age data
        + some length
        + med var fishery indep indices of abundance
- Two parts: 
    + Operating model simulates
        * Biomass (proc error)
        * survey CPUE (obs error)
        * Catch (as a proportion of biomass) (development - overexploitation - F_MSY)
    + Estimator: HBM schaeffer model (fully Bayesian state space model)
        - Likelihood on obs error
        - priors:
            + proc error var (separate prior for each stock - fixed parameters)
            + proc error devs (separate prior for each stock - fixed parameters)
            + obs error var (separate prior for each stock - fixed parameters)
            + growth rate (separate prior for each stock - fixed parameters)
            + MSY (separate prior for each stock - fixed parameters)
            + lnq ( shared prior, estimated hyper-parameters )
            + hyper-priors on hyper-parameters for lnq prior (fixed parameters)
- What is the bias and precision on key management parameters of each stock in a Hierarchical fully Bayesian Schaeffer model, sharing a prior on catchability?
    + (>=)100 replicates of each scenario
        * varying contrasts in productivity (rate of growth), obs error variance, catchability
        * test a "continuum" of values for the variance on the lnq parameter (a l\'{a} @gelman2014bayesian Ch 5) to get a smooth curve of error rates for different testing parameters
        * Compare posterior median and mode values to "real" simulated values and generate distributions of errors to estimate bias and precision in the method.


- **A simulation test of the model's bias and precision has not yet been performed, so we propose one here**
- Follow the formulation and analysis in @gelman2014bayesian Chapter 5 on Hierarchical models (8 schools) - though we go for 3 stocks
- Bayesian methods (@gelman2014bayesian)
    + works on probabilities as degrees of belief rather than as a limiting frequency of events
    + Incorporates inherent subjectivity through the use of prior distributions - sometimes informative and developed through expert inference, sometimes vague/uninformative
    + Useful for providing distributions of parameter estimates, rather than maximum likelihood estimates often produced by likelihood methods
    + requires integration over the parameter space to provide marginal/conditional densities - in practice for non-linear models this is often numerical.

Guiding question:
**What are the bias and precision in estimates of stock assessment parameters of interest (depletion, unfished biomass, fishing mortality) from an assemblage-based  hierarchical bayesian stock assessment method (compared to single-species approaches)?**






### Operating model

**NOTE: Missing table and equation references: These are set up for Latex compilation, which initial drafts skip for ease of editing.**

The operating model for our simulation test is outlined below. The operating model simulates biomass for each stock according to a Schaeffer population dynamics model (ref) with log-normal process error, from which catch is computed. Survey Catch Per Unit Effort (CPUE) for each stock is then generated from the biomass time series in an observation model where log-normal observation error is applied. Time series for biomass, catch and CPUE are then saved, with catch and CPUE passed to an estimator for model testing.

#### Population Dynamics Model

For $s \in \{1,2,3\}$ and $t \in \{1,...,T\}$, the population of stock $s$ grows according to the Schaefer model
$$
B_{t+1,s} = \left(B_{t,s} + r_s \cdot B_{t,s} \cdot \left(1 - \frac{B_{t,s}}{B_{0,s}}\right) - C_{t,s}\right) \cdot e^{\delta_{t,s}}, \label{eq:bioModel}
$$
where $B_{t,s}$ is the biomass of stock $s$ present at the beginning of year $t$, $r_s$ is the intrinsic rate of growth of stock $s$, $B_{0,s}$ is the unfished biomass of stock $s$ and $C_{t,s}$ is the total caught weight of stock $s$ in year $t$. The catch is computed as $C_{t,s} = \left(1 - e^{-F_{t,s}}\right) \cdot B_{t,s}$, where $F_{t,s}$ is the instantaneous fishing mortality for stock $s$ in year $t$. The factor $e^{\delta_{t,s}}$ is the log-normally distributed process error deviation from the mean biomass produced by the Schaefer model.


#### Observation Model

Survey CPUE is simulated as
$$
I_{t,s} = q_s \cdot B_{t,s} \cdot e^{\epsilon_{t,s}}, \label{eq:obsModOper}
$$
where $q_s$ is the catchability coefficient for stock $s$, $B_{t,s}$ is as above and the factor $e^{\epsilon_{t,s}}$ is the log-normally distributed observation error deviation from true CPUE.

### Estimator

We pass the catch and CPUE data generated by the operating model to an estimator consisting of a population dynamics model, an observation model and a statistical model. The estimator numerically integrates the statistical model over the parameter space to produce a posterior density function, marginal densities of any leading parameters and conditional densities of any derived variables produced by the estimator, listed in Table \ref{tab:modelPars} and grouped together as the vector $\Theta$.

#### Population dynamics

The population dynamics model for the estimator is implemented identically to Eq \ref{eq:bioModel}, where now $\bar{B}_{t,s}$ is the estimated biomass at time $t$ for stock $s$.

#### Observation Model

The expected CPUE is estimated as
$$
\bar{I_{t,s}} = \bar{q}_s \cdot \bar{B}_{t,s},
$$
to be passed to the statistical model for calculation of the observation error likelihood.

#### Statistical model

The statistical model is a hierarchical Bayesian model incorporating a likelihood on the observation error and priors on leading parameters $\theta \in \Theta$ and process error deviations. The statistical model written as a the formula for the posterior density $P$ for parameters $\Theta$ is given by Bayes' Theorem (*REFS*) as
$$
P \left( \Theta ~|~ \vec{C}, \vec{I} ~ \right) 
    = \frac { \mathcal{L} \left( \Theta ~|~ \vec{C}, \vec{I} ~ \right)
              \prod_{\theta \in \Theta} p_{\theta} ( \theta ) }
            { \int_{\Theta} \mathcal{L} \left( \Theta ~|~ \vec{C}, \vec{I} ~\right) \prod_{\theta \in \Theta} p_{\theta} ( \theta ) }. 
        \label{eq:postFull}
$$
Here, the priors $p_\theta(\theta)$ on all leading parameters except for catchability are separated by stock and have fixed hyper-parameters, each taking the form of a probability density function. The prior density on catchability is applied to the logarithm $\log q_s$, and has estimated hyperparameters $m_{\log q}$ and $s^2_{\log q}$ that are included in $\Theta$. Finally, the hyperparameters of $p_q$ have their own priors with fixed parameters. All likelihoods and prior densities are completeley specified in Table \ref{tab:modTable}.

### Parameter Estimation and Comparison

The estimator, specified in Table \ref{tab:modelSpec} is coded in ``ADMB`` *(refs)* to integrate marginal and conditional posterior densities for the leading parameters and derived variables listed in Table \ref{tab:modelPars}. Numerical integration is performed by the Metropolis-Hastings Markov-Chain Monte-Carlo (MCMC) algorithm in ``ADMB``. For 100 simulation replicates, posterior medians and modes for each parameter are compared to "real" values from the operating model. Each replicate contributes error values to a distribution of errors for each parameter, from which bias and precision are estimated.

Elaborations:
- Gelman-Rubin chain diagnostics for convergence to stationary distribution
- combinatorial design of scenarios
 -->